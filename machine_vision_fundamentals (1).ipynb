{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Vision Fundamentals\n",
    "\n",
    "**Author:** Grok AI\n",
    "**Date:** September 14, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook introduces the fundamentals of machine vision using Python, NumPy, OpenCV, scikit-image, and matplotlib. It is designed for interns or beginners, providing clear explanations, code examples, and visualizations. By the end, you will learn:\n",
    "\n",
    "- Basic image handling and properties\n",
    "- Histogram analysis and contrast enhancement\n",
    "- Geometric transformations\n",
    "- Filtering and denoising\n",
    "- Edge detection\n",
    "- Morphological operations\n",
    "- Feature detection and matching\n",
    "- Simple image segmentation\n",
    "- (Optional) Introduction to deep learning for feature extraction\n",
    "\n",
    "The notebook uses sample images from scikit-image for reproducibility, so no external downloads are needed. Run the cells sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import skimage\n",
    "import matplotlib\n",
    "import scipy\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"scikit-image version: {skimage.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "print(f\"SciPy version: {scipy.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Basics\n",
    "\n",
    "Images in machine vision are represented as arrays of pixels. Key concepts:\n",
    "\n",
    "- **Pixels**: The smallest unit of an image, holding intensity values.\n",
    "- **Dimensions**: Width (columns), height (rows), channels (e.g., 3 for RGB).\n",
    "- **Data Type (dtype)**: Often uint8 (0-255) for images.\n",
    "- **Color Spaces**: RGB (Red-Green-Blue), BGR (OpenCV default), Grayscale (single channel).\n",
    "\n",
    "We'll load images using OpenCV (cv2) and scikit-image, noting that cv2 uses BGR by default, while matplotlib expects RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load sample images from scikit-image\n",
    "color_image = data.astronaut()  # RGB color image\n",
    "gray_image = data.camera()  # Grayscale image\n",
    "\n",
    "# Save temporarily and load with OpenCV to demonstrate I/O\n",
    "from skimage.io import imsave, imread\n",
    "imsave('temp_color.png', color_image)\n",
    "imsave('temp_gray.png', gray_image)\n",
    "\n",
    "cv_color = cv2.imread('temp_color.png')  # Loads as BGR\n",
    "cv_gray = cv2.imread('temp_gray.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Display with matplotlib (convert BGR to RGB for cv_color)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(cv_color[:,:,::-1])  # BGR to RGB\n",
    "axs[0].set_title('Color Image (RGB)')\n",
    "axs[1].imshow(cv_gray, cmap='gray')\n",
    "axs[1].set_title('Grayscale Image')\n",
    "plt.show()\n",
    "\n",
    "# Clean up temp files\n",
    "import os\n",
    "os.remove('temp_color.png')\n",
    "os.remove('temp_gray.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Color Image Shape:\", color_image.shape)\n",
    "print(\"Color Image Dtype:\", color_image.dtype)\n",
    "print(\"Color Image Min/Max:\", color_image.min(), color_image.max())\n",
    "\n",
    "print(\"\\nGrayscale Image Shape:\", gray_image.shape)\n",
    "print(\"Grayscale Image Dtype:\", gray_image.dtype)\n",
    "print(\"Grayscale Image Min/Max:\", gray_image.min(), gray_image.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB to BGR\n",
    "bgr_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Convert color to grayscale\n",
    "gray_from_color = cv2.cvtColor(color_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Differences: Grayscale reduces channels to 1, losing color info. BGR vs RGB is channel order.\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(color_image)\n",
    "axs[0].set_title('RGB')\n",
    "axs[1].imshow(bgr_image[:,:,::-1])  # Show as RGB for consistency\n",
    "axs[1].set_title('BGR (displayed as RGB)')\n",
    "axs[2].imshow(gray_from_color, cmap='gray')\n",
    "axs[2].set_title('Grayscale from Color')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms and Contrast\n",
    "\n",
    "A histogram shows the distribution of pixel intensities. For grayscale, it's a plot of intensity (0-255) vs frequency.\n",
    "\n",
    "Contrast adjustment improves visibility: linear rescale stretches values, histogram equalization spreads them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import equalize_hist\n",
    "\n",
    "# Grayscale histogram\n",
    "hist, bins = np.histogram(gray_image.ravel(), bins=256, range=(0, 256))\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(bins[:-1], hist, width=1)\n",
    "plt.title('Grayscale Histogram')\n",
    "plt.xlabel('Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Interpretation: Peaks indicate common intensities; flat means low contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity, equalize_adapthist\n",
    "\n",
    "# Linear rescale\n",
    "rescaled = rescale_intensity(gray_image, in_range='image', out_range=(0, 255))\n",
    "\n",
    "# Histogram equalization\n",
    "equalized = (equalize_hist(gray_image) * 255).astype(np.uint8)\n",
    "\n",
    "# CLAHE (optional)\n",
    "clahe = (equalize_adapthist(gray_image) * 255).astype(np.uint8)\n",
    "\n",
    "# Plot histograms before/after\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axs[0,0].hist(gray_image.ravel(), bins=256)\n",
    "axs[0,0].set_title('Original')\n",
    "axs[0,1].hist(rescaled.ravel(), bins=256)\n",
    "axs[0,1].set_title('Rescaled')\n",
    "axs[1,0].hist(equalized.ravel(), bins=256)\n",
    "axs[1,0].set_title('Equalized')\n",
    "axs[1,1].hist(clahe.ravel(), bins=256)\n",
    "axs[1,1].set_title('CLAHE')\n",
    "plt.show()\n",
    "\n",
    "# Discussion: Equalization spreads histogram, revealing details in dark/bright areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Transforms\n",
    "\n",
    "These change image size or orientation: resize (scale), crop (slice), rotate.\n",
    "\n",
    "Interpolation methods: nearest (fast, blocky), bilinear (smooth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize, rotate\n",
    "\n",
    "# Resize\n",
    "small = resize(color_image, (color_image.shape[0]//2, color_image.shape[1]//2), anti_aliasing=True)\n",
    "large = resize(color_image, (color_image.shape[0]*2, color_image.shape[1]*2), order=3)  # Bicubic\n",
    "\n",
    "# Crop (array slicing)\n",
    "crop = color_image[100:400, 100:400]\n",
    "\n",
    "# Rotate\n",
    "rotated = rotate(color_image, 30, mode='wrap')\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "axs[0,0].imshow(small)\n",
    "axs[0,0].set_title('2x Smaller (Bilinear)')\n",
    "axs[0,1].imshow(large)\n",
    "axs[0,1].set_title('2x Larger (Bicubic)')\n",
    "axs[1,0].imshow(crop)\n",
    "axs[1,0].set_title('Cropped')\n",
    "axs[1,1].imshow(rotated)\n",
    "axs[1,1].set_title('30° Rotated')\n",
    "plt.show()\n",
    "\n",
    "# Interpolation differences: Nearest would show artifacts in enlargement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and Denoising\n",
    "\n",
    "Filters smooth or enhance: mean (box) blur averages, Gaussian weights by distance, median good for salt-pepper noise.\n",
    "\n",
    "Add noise: Gaussian (normal dist), salt-pepper (random pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.util import random_noise\n",
    "from skimage.filters import gaussian, median\n",
    "from skimage.morphology import disk\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "np.random.seed(42)  # Reproducibility\n",
    "\n",
    "# Add Gaussian noise\n",
    "noisy_gauss = random_noise(gray_image, mode='gaussian', var=0.01)\n",
    "\n",
    "# Add salt-and-pepper noise\n",
    "noisy_sp = random_noise(gray_image, mode='s&p', amount=0.05)\n",
    "\n",
    "# Denoise\n",
    "blur_mean = cv2.blur(noisy_gauss, (3,3))\n",
    "blur_gauss = gaussian(noisy_gauss, sigma=1)\n",
    "median_sp = median(noisy_sp, disk(1))\n",
    "\n",
    "# Compare PSNR\n",
    "psnr_gauss = psnr(gray_image / 255.0, noisy_gauss)\n",
    "psnr_denoised_gauss = psnr(gray_image / 255.0, blur_gauss)\n",
    "psnr_sp = psnr(gray_image / 255.0, noisy_sp)\n",
    "psnr_denoised_sp = psnr(gray_image / 255.0, median_sp)\n",
    "\n",
    "print(f\"Gaussian Noise PSNR: {psnr_gauss:.2f}, Denoised: {psnr_denoised_gauss:.2f}\")\n",
    "print(f\"S&P Noise PSNR: {psnr_sp:.2f}, Denoised: {psnr_denoised_sp:.2f}\")\n",
    "\n",
    "# Viz\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axs[0,0].imshow(noisy_gauss, cmap='gray')\n",
    "axs[0,0].set_title('Gaussian Noisy')\n",
    "axs[0,1].imshow(blur_mean, cmap='gray')\n",
    "axs[0,1].set_title('Mean Blur')\n",
    "axs[0,2].imshow(blur_gauss, cmap='gray')\n",
    "axs[0,2].set_title('Gaussian Blur')\n",
    "axs[1,0].imshow(noisy_sp, cmap='gray')\n",
    "axs[1,0].set_title('S&P Noisy')\n",
    "axs[1,1].imshow(median_sp, cmap='gray')\n",
    "axs[1,1].set_title('Median Filter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection\n",
    "\n",
    "Edges are abrupt intensity changes. Gradient: rate of change (Sobel for x/y).\n",
    "\n",
    "Canny: multi-stage, uses thresholds for strong/weak edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import sobel\n",
    "from skimage.feature import canny\n",
    "\n",
    "# Sobel magnitude\n",
    "sobel_mag = sobel(gray_image / 255.0)\n",
    "\n",
    "# Canny\n",
    "canny_edges = canny(gray_image / 255.0, sigma=1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(gray_image, cmap='gray')\n",
    "axs[0].set_title('Original')\n",
    "axs[1].imshow(sobel_mag, cmap='gray')\n",
    "axs[1].set_title('Sobel Magnitude')\n",
    "axs[2].imshow(canny_edges, cmap='gray')\n",
    "axs[2].set_title('Canny Edges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Operations\n",
    "\n",
    "For binary images: erosion shrinks, dilation expands, opening removes noise, closing fills holes.\n",
    "\n",
    "Structuring element (kernel): shape/size affects result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import binary_erosion, binary_dilation, binary_opening, binary_closing, square\n",
    "\n",
    "# Threshold to binary\n",
    "_, binary = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "binary = binary.astype(bool)  # For skimage\n",
    "\n",
    "# Operations with square kernel\n",
    "eroded = binary_erosion(binary, square(3))\n",
    "dilated = binary_dilation(binary, square(3))\n",
    "opened = binary_opening(binary, square(3))\n",
    "closed = binary_closing(binary, square(3))\n",
    "\n",
    "# Show effects\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axs[0,0].imshow(binary, cmap='gray')\n",
    "axs[0,0].set_title('Binary')\n",
    "axs[0,1].imshow(eroded, cmap='gray')\n",
    "axs[0,1].set_title('Eroded (3x3)')\n",
    "axs[0,2].imshow(dilated, cmap='gray')\n",
    "axs[0,2].set_title('Dilated (3x3)')\n",
    "axs[1,0].imshow(opened, cmap='gray')\n",
    "axs[1,0].set_title('Opened (3x3)')\n",
    "axs[1,1].imshow(binary_closing(binary, square(5)), cmap='gray')\n",
    "axs[1,1].set_title('Closed (5x5)')\n",
    "plt.show()\n",
    "\n",
    "# Larger kernel smooths more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Detection and Description\n",
    "\n",
    "Features are distinctive points (keypoints) with descriptors.\n",
    "\n",
    "ORB: Oriented FAST and Rotated BRIEF, rotation/scale invariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rotated image\n",
    "rotated_color = rotate(color_image, 30, mode='wrap')\n",
    "\n",
    "# ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Detect keypoints and descriptors\n",
    "kp1, des1 = orb.detectAndCompute(cv2.cvtColor(color_image, cv2.COLOR_RGB2GRAY), None)\n",
    "kp2, des2 = orb.detectAndCompute(cv2.cvtColor(rotated_color, cv2.COLOR_RGB2GRAY), None)\n",
    "\n",
    "# Matcher\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des1, des2)\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "# Draw\n",
    "img_kp1 = cv2.drawKeypoints(color_image, kp1, None, color=(0,255,0))\n",
    "img_kp2 = cv2.drawKeypoints(rotated_color, kp2, None, color=(0,255,0))\n",
    "img_matches = cv2.drawMatches(color_image, kp1, rotated_color, kp2, matches[:50], None, flags=2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 7))\n",
    "axs[0].imshow(img_kp1[:,:,::-1])\n",
    "axs[0].set_title('Keypoints Original')\n",
    "axs[1].imshow(img_kp2[:,:,::-1])\n",
    "axs[1].set_title('Keypoints Rotated')\n",
    "axs[2].imshow(img_matches[:,:,::-1])\n",
    "axs[2].set_title('Top 50 Matches')\n",
    "plt.show()\n",
    "\n",
    "# Observation: ORB finds matches despite rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Segmentation\n",
    "\n",
    "Segmentation separates foreground/background. Thresholding: pixels above threshold are foreground.\n",
    "Otsu: automatic threshold selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "# Global fixed\n",
    "_, thresh_fixed = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Otsu\n",
    "thresh_otsu = threshold_otsu(gray_image)\n",
    "thresh_otsu_img = gray_image > thresh_otsu\n",
    "\n",
    "# Foreground ratio\n",
    "fg_fixed = np.sum(thresh_fixed > 0) / thresh_fixed.size\n",
    "fg_otsu = np.sum(thresh_otsu_img) / thresh_otsu_img.size\n",
    "\n",
    "print(f\"Fixed Threshold FG Ratio: {fg_fixed:.2f}\")\n",
    "print(f\"Otsu FG Ratio: {fg_otsu:.2f}\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(gray_image, cmap='gray')\n",
    "axs[0].set_title('Original')\n",
    "axs[1].imshow(thresh_fixed, cmap='gray')\n",
    "axs[1].set_title('Fixed Threshold')\n",
    "axs[2].imshow(thresh_otsu_img, cmap='gray')\n",
    "axs[2].set_title('Otsu Threshold')\n",
    "plt.show()\n",
    "\n",
    "# Compare: Otsu adapts to lighting, better for varying conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Deep Learning Intro\n",
    "\n",
    "Use a pretrained CNN to classify an image. Requires torch and torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Load pretrained ResNet18\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Preprocess image\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(color_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "probabilities = F.softmax(output[0], dim=0)\n",
    "\n",
    "# Top 5 classes (load labels)\n",
    "!wget -q https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "\n",
    "# Visualize probabilities (bar plot)\n",
    "plt.barh(categories[top5_catid.numpy()], top5_prob.numpy())\n",
    "plt.title('Top 5 Class Probabilities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1\n",
    "Implement a function that takes an image and returns a contrast-stretched version limited to the 2nd–98th percentile of intensities. Test on grayscale and color images; show before/after histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Implement a mini pipeline: (a) grayscale, (b) median denoise, (c) Otsu threshold, (d) opening clean, (e) Canny on cleaned mask. Count edge pixels, display 2x3 grid intermediates. Discuss parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "(Toggle or scroll to view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_stretch(img, low_p=2, high_p=98):\n",
    "    if len(img.shape) == 3:  # Color\n",
    "        out = np.zeros_like(img)\n",
    "        for c in range(3):\n",
    "            p_low, p_high = np.percentile(img[:,:,c], [low_p, high_p])\n",
    "            out[:,:,c] = rescale_intensity(img[:,:,c], in_range=(p_low, p_high), out_range=(0, 255))\n",
    "        return out.astype(np.uint8)\n",
    "    else:  # Grayscale\n",
    "        p_low, p_high = np.percentile(img, [low_p, high_p])\n",
    "        return rescale_intensity(img, in_range=(p_low, p_high), out_range=(0, 255)).astype(np.uint8)\n",
    "\n",
    "# Test grayscale\n",
    "stretched_gray = contrast_stretch(gray_image)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axs[0].hist(gray_image.ravel(), bins=256)\n",
    "axs[0].set_title('Before')\n",
    "axs[1].hist(stretched_gray.ravel(), bins=256)\n",
    "axs[1].set_title('After')\n",
    "plt.show()\n",
    "\n",
    "# Test color\n",
    "stretched_color = contrast_stretch(color_image)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(color_image)\n",
    "axs[0].set_title('Before')\n",
    "axs[1].imshow(stretched_color)\n",
    "axs[1].set_title('After')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_pipeline(img, median_size=3, open_size=3, canny_sigma=1):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    denoised = median(gray, disk(median_size))\n",
    "    thresh_val = threshold_otsu(denoised)\n",
    "    binary = denoised > thresh_val\n",
    "    cleaned = binary_opening(binary, square(open_size))\n",
    "    edges = canny(cleaned.astype(float), sigma=canny_sigma)\n",
    "    \n",
    "    edge_count = np.sum(edges)\n",
    "    print(f\"Edge pixels: {edge_count}\")\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axs[0,0].imshow(gray, cmap='gray'); axs[0,0].set_title('Grayscale')\n",
    "    axs[0,1].imshow(denoised, cmap='gray'); axs[0,1].set_title('Denoised')\n",
    "    axs[0,2].imshow(binary, cmap='gray'); axs[0,2].set_title('Otsu Threshold')\n",
    "    axs[1,0].imshow(cleaned, cmap='gray'); axs[1,0].set_title('Cleaned')\n",
    "    axs[1,1].imshow(edges, cmap='gray'); axs[1,1].set_title('Canny Edges')\n",
    "    axs[1,2].axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return edges\n",
    "\n",
    "# Run on color_image\n",
    "_ = mini_pipeline(color_image)\n",
    "\n",
    "# Discussion: Median size=3 removes small noise; open_size=3 cleans specks; sigma=1 for fine edges. Adjust for image scale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}